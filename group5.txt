Group by SF-295
Test number: 0/3

[NEW TEST]  - Model info:
{
	"data": "SF-295",
	"lr": 0.001,
	"batchsize": 256,
	"nepoch": 100,
	"hdim": 128,
	"width": 4,
	"depth": 6,
	"dropout": 0.4,
	"normalize": 1,
	"beta": 0.999,
	"gamma": 1.5,
	"decay": 0,
	"seed": 10,
	"patience": 50,
	"intergraph": "sage",
	"alltests": 1,
	"datagroup": 5
}
Loading dataset: SF-295
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):
/usr/local/lib/python3.10/dist-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location)
Starts training...
Epoch: 0, loss: 0.21623553308817717, time cost: 138.11953902244568
Val auc: 0.7428657353467336, f1: 0.584275815624852, accuracy: 0.9458698890912101, precision: 0.6719450503095089, recall: 0.5602987991156206
Epoch: 1, loss: 0.150965616106987, time cost: 153.2607500553131
Val auc: 0.7556173912644606, f1: 0.5177982347668492, accuracy: 0.9495116702532693, precision: 0.7136766334440753, recall: 0.5154886792106639
Epoch: 2, loss: 0.14699991866274997, time cost: 138.2652885913849
Val auc: 0.7420211485004999, f1: 0.5970267446360804, accuracy: 0.9331236550240026, precision: 0.6154050381846293, recall: 0.5847396401933892
Epoch: 3, loss: 0.1454676243367496, time cost: 141.6884138584137
Val auc: 0.7464020485674706, f1: 0.5642934587898101, accuracy: 0.949346134745903, precision: 0.7183139585146421, recall: 0.5434380246415237
Epoch: 4, loss: 0.14327476804589365, time cost: 140.40924334526062
Val auc: 0.762556993844206, f1: 0.5902339059184063, accuracy: 0.9491805992385367, precision: 0.7188087698224923, recall: 0.5620418704072365
Epoch: 5, loss: 0.1396295618232306, time cost: 144.3094460964203
Val auc: 0.7828179040943826, f1: 0.5871106070808378, accuracy: 0.9463664956133091, precision: 0.6788386174473158, recall: 0.5621178430868875
Epoch: 6, loss: 0.13566579428073522, time cost: 147.72501039505005
Val auc: 0.7923749805051238, f1: 0.5553710903401436, accuracy: 0.9514980963416653, precision: 0.8051781551781552, recall: 0.5367831045934516
Epoch: 7, loss: 0.13186761038797395, time cost: 142.49117827415466
Val auc: 0.8016786235241232, f1: 0.5093183104288909, accuracy: 0.9500082767753684, precision: 0.7670357162602974, recall: 0.511077390071833
Epoch: 8, loss: 0.12968668566496522, time cost: 141.25784611701965
Val auc: 0.8199143601552251, f1: 0.6078545926647193, accuracy: 0.9510014898195663, precision: 0.7516773084958897, recall: 0.5739036425602965
Epoch: 9, loss: 0.12709660163602313, time cost: 141.6494209766388
Val auc: 0.8037187049897709, f1: 0.5874039607247337, accuracy: 0.9465320311206754, precision: 0.6808322498916559, recall: 0.5622049966514683
Epoch: 10, loss: 0.1250533015878351, time cost: 142.06966400146484
Val auc: 0.8361048549122502, f1: 0.5326907605668668, accuracy: 0.950339347790101, precision: 0.7644382633160688, recall: 0.5237123634211902
Epoch: 11, loss: 0.12363726242973998, time cost: 143.45762848854065
Val auc: 0.8302122418649028, f1: 0.5800275931268031, accuracy: 0.951829167356398, precision: 0.788692164202619, recall: 0.5525332444978579
Epoch: 12, loss: 0.1209381238834278, time cost: 143.1540288925171
Val auc: 0.8304071906277809, f1: 0.5677430761863107, accuracy: 0.9514980963416653, precision: 0.7880957675487362, recall: 0.5445710209810739
Epoch: 13, loss: 0.12078402929746353, time cost: 146.8557801246643
Val auc: 0.8241843114409695, f1: 0.5211082971614809, accuracy: 0.9500082767753684, precision: 0.7506684936057133, recall: 0.5173077231819307
Epoch: 14, loss: 0.11719644197204092, time cost: 146.03990173339844
Val auc: 0.844629849637166, f1: 0.6260040895339738, accuracy: 0.9531534514153286, precision: 0.7893505380329654, recall: 0.5859397218425181
Epoch: 15, loss: 0.11593278839781478, time cost: 143.97526216506958
Val auc: 0.8406253726961643, f1: 0.6050757096893596, accuracy: 0.9524913093858632, precision: 0.7880836105409676, recall: 0.5700152748089502
Epoch: 16, loss: 0.11375178124856304, time cost: 146.67614698410034
Val auc: 0.8410324715833508, f1: 0.662807874260499, accuracy: 0.9554709485184573, precision: 0.8107202731878724, recall: 0.6151963707420897
Epoch: 17, loss: 0.11171501156714586, time cost: 147.123779296875
Val auc: 0.8511302441217213, f1: 0.6745572308486216, accuracy: 0.952822380400596, precision: 0.7628661217238781, recall: 0.6340504963166151
Epoch: 18, loss: 0.11012941780122551, time cost: 145.36343669891357
Val auc: 0.842587474656661, f1: 0.5921068179132695, accuracy: 0.9523257738784969, precision: 0.7944295825670178, recall: 0.5605826215792227
Epoch: 19, loss: 0.10977557734460444, time cost: 146.69344091415405
Val auc: 0.8473769070576039, f1: 0.6686377363711449, accuracy: 0.9480218506869723, precision: 0.7185546330361882, recall: 0.6393109593313946
Epoch: 20, loss: 0.10968145278391538, time cost: 142.63565945625305
Val auc: 0.849868237571443, f1: 0.6256079677379934, accuracy: 0.9529879159079623, precision: 0.7858203655910694, recall: 0.5858525682779373
Epoch: 21, loss: 0.10637645104581171, time cost: 149.65930676460266
Val auc: 0.8601380237241177, f1: 0.6869372893441092, accuracy: 0.9485184572090714, precision: 0.7246960298262002, recall: 0.6613785859104795
Epoch: 22, loss: 0.1048820807791508, time cost: 149.2144639492035
Val auc: 0.8540378475821766, f1: 0.6599920963763083, accuracy: 0.9533189869226949, precision: 0.7742086972856204, recall: 0.6171785409575883
Epoch: 23, loss: 0.10123751933375995, time cost: 149.8928472995758
Val auc: 0.8531084006862196, f1: 0.6284645583274124, accuracy: 0.9526568448932295, precision: 0.7770214912578843, recall: 0.5887934277038247
Epoch: 24, loss: 0.10145287051259934, time cost: 144.98434591293335
Val auc: 0.8651470601726557, f1: 0.6639086793970644, accuracy: 0.9553054130110908, precision: 0.8064123376623377, recall: 0.6166668004550333
Epoch: 25, loss: 0.09965872979378915, time cost: 150.84579467773438
Val auc: 0.8650277974000715, f1: 0.6974580668166439, accuracy: 0.9544777354742592, precision: 0.775443686213179, recall: 0.6567281978477657
Epoch: 26, loss: 0.09859035063434292, time cost: 148.17757654190063
Val auc: 0.857853682926158, f1: 0.6615518715016834, accuracy: 0.9572918390994868, precision: 0.8579491775425232, recall: 0.6099247268423805
Epoch: 27, loss: 0.09568130248435983, time cost: 144.49165654182434
Val auc: 0.8644730534939405, f1: 0.696446517457052, accuracy: 0.9549743419963582, precision: 0.781777681179507, recall: 0.6538744919864591
Epoch: 28, loss: 0.0958654496248241, time cost: 146.45143294334412
Val auc: 0.864567947671165, f1: 0.7204485047026692, accuracy: 0.9514980963416653, precision: 0.7460416050478162, recall: 0.7003293487335212
Epoch: 29, loss: 0.09267682612345025, time cost: 144.4517903327942
Val auc: 0.85956063135877, f1: 0.6625206653765238, accuracy: 0.9548088064889919, precision: 0.7979009229775933, recall: 0.616405339761291
Epoch: 30, loss: 0.09138334126354337, time cost: 144.4725625514984
Val auc: 0.869094772620937, f1: 0.7237451497024632, accuracy: 0.9533189869226949, precision: 0.7585972630618093, recall: 0.6981728713888609
Epoch: 31, loss: 0.08881600389072487, time cost: 145.00659322738647
Val auc: 0.8551851783895854, f1: 0.7006442569194121, accuracy: 0.9551398775037245, precision: 0.7820365397906943, recall: 0.6586343953836133
Epoch: 32, loss: 0.08826702299552995, time cost: 142.98981952667236
Val auc: 0.8606466106437437, f1: 0.7081175298086506, accuracy: 0.9556364840258236, precision: 0.7847648742528344, recall: 0.666683772464978
Epoch: 33, loss: 0.08776400385944692, time cost: 146.67316365242004
Val auc: 0.8692868544902436, f1: 0.6596423576286087, accuracy: 0.9566296970700215, precision: 0.841860190548426, recall: 0.6095761125840573
Epoch: 34, loss: 0.0885570778234585, time cost: 150.92386865615845
Val auc: 0.8632801390787408, f1: 0.7210799791164259, accuracy: 0.9548088064889919, precision: 0.7715842827072351, recall: 0.6880541705274167
Epoch: 35, loss: 0.08391671322353252, time cost: 150.90699529647827
Val auc: 0.8665592919460933, f1: 0.7120928715743862, accuracy: 0.9558020195331899, precision: 0.7849581339142933, recall: 0.6714436758621323
Epoch: 36, loss: 0.08483849579955006, time cost: 146.58154559135437
Val auc: 0.861411497848683, f1: 0.6336608582109452, accuracy: 0.9533189869226949, precision: 0.7878279411396413, recall: 0.5922572085171968
Epoch: 37, loss: 0.08313046795156626, time cost: 147.35554242134094
Val auc: 0.868959455244351, f1: 0.7105109944979313, accuracy: 0.9567952325773879, precision: 0.7981331353012768, recall: 0.6657362641395191
Epoch: 38, loss: 0.08043956847206966, time cost: 147.23892736434937
Val auc: 0.8643652582956431, f1: 0.6625206653765238, accuracy: 0.9548088064889919, precision: 0.7979009229775933, recall: 0.616405339761291
Epoch: 39, loss: 0.08026476768223015, time cost: 149.9435329437256
Val auc: 0.861351866462391, f1: 0.6749933040103173, accuracy: 0.9539811289521603, precision: 0.7777029317064904, recall: 0.6315454047136317
Epoch: 40, loss: 0.08050974391333691, time cost: 148.01675724983215
Val auc: 0.8776472895241416, f1: 0.7124558148060556, accuracy: 0.9577884456215858, precision: 0.8109452601679172, recall: 0.6647016022494794
Epoch: 41, loss: 0.07802993891475436, time cost: 149.15751481056213
Val auc: 0.8654383365595442, f1: 0.7333880319160265, accuracy: 0.9571263035921205, precision: 0.7900024807740015, recall: 0.6970622368191701
Epoch: 42, loss: 0.07824079011071909, time cost: 150.31315732002258
Val auc: 0.8731216113317982, f1: 0.7080083055908869, accuracy: 0.9521602383711306, precision: 0.7513050160951985, recall: 0.6788717971065017
Epoch: 43, loss: 0.081008956205469, time cost: 148.3438310623169
Val auc: 0.8732964918396742, f1: 0.7079453177834054, accuracy: 0.9571263035921205, precision: 0.8044058810030007, recall: 0.6612378214361072
Epoch: 44, loss: 0.07548933600385983, time cost: 148.92373919487
Val auc: 0.8700253662743228, f1: 0.7183183967322883, accuracy: 0.9577884456215858, precision: 0.8066696025721795, recall: 0.6724895186371017
Epoch: 45, loss: 0.07297426973981364, time cost: 150.17714858055115
Val auc: 0.8718790996578075, f1: 0.7051297673152539, accuracy: 0.9546432709816256, precision: 0.7746900415173748, recall: 0.6661608510774932
Epoch: 46, loss: 0.07319635894518715, time cost: 149.18694257736206
Val auc: 0.8683172710842821, f1: 0.7384918184847632, accuracy: 0.9577884456215858, precision: 0.7945916013306809, recall: 0.7020836009100667
Epoch: 47, loss: 0.07325764070894267, time cost: 147.67702388763428
Val auc: 0.8736221709494234, f1: 0.726682787346241, accuracy: 0.9569607680847542, precision: 0.7913915127942098, recall: 0.6876295835894425
Epoch: 48, loss: 0.06988330061237018, time cost: 148.62884831428528
Val auc: 0.869413571186114, f1: 0.7067646972948511, accuracy: 0.9559675550405562, precision: 0.789435410636245, recall: 0.6637429130390907
Epoch: 49, loss: 0.06874696395217299, time cost: 148.40104389190674
Val auc: 0.8703195095547827, f1: 0.7343897293629555, accuracy: 0.9571263035921205, precision: 0.7895422023103027, recall: 0.6986198200966945
Epoch: 50, loss: 0.06832865382301377, time cost: 148.65879321098328
Val auc: 0.862887374659413, f1: 0.7271197140636123, accuracy: 0.9524913093858632, precision: 0.7523635367593728, recall: 0.7070826032311037
Epoch: 51, loss: 0.06933417248430553, time cost: 150.4428572654724
Val auc: 0.868880042292414, f1: 0.691180107550758, accuracy: 0.9571263035921205, precision: 0.8176037509202929, recall: 0.6409892388282892
Epoch: 52, loss: 0.06629782881554183, time cost: 149.39975094795227
Val auc: 0.8710826766235792, f1: 0.7360447673898534, accuracy: 0.9579539811289521, precision: 0.797728266751029, recall: 0.6974980046420741
Epoch: 53, loss: 0.06656403906710513, time cost: 150.49838876724243
Val auc: 0.8716807106226434, f1: 0.7338059140342823, accuracy: 0.9538155934447939, precision: 0.76093118406783, recall: 0.7124525815803235
Epoch: 54, loss: 0.06341116340109357, time cost: 146.63375043869019
Val auc: 0.8662660087337046, f1: 0.739530518033545, accuracy: 0.9548088064889919, precision: 0.7673124322192645, recall: 0.7176482528003816
Epoch: 55, loss: 0.066645329230809, time cost: 153.2413477897644
Val auc: 0.8674583497701899, f1: 0.7409848158282369, accuracy: 0.9538155934447939, precision: 0.7600190245131182, recall: 0.7249132478005192
Epoch: 56, loss: 0.0639301627236712, time cost: 149.18761253356934
Val auc: 0.8669606570461363, f1: 0.6768686261342163, accuracy: 0.9546432709816256, precision: 0.7864341037007521, recall: 0.6318940189719549
Epoch: 57, loss: 0.061588317357205054, time cost: 150.0928885936737
Val auc: 0.8733948262891849, f1: 0.7483590360626634, accuracy: 0.9567952325773879, precision: 0.7809321991118342, recall: 0.7233668454079246
Epoch: 58, loss: 0.060655267103701026, time cost: 147.14750838279724
Val auc: 0.8611987743456603, f1: 0.718412314542907, accuracy: 0.9549743419963582, precision: 0.7739068652627974, recall: 0.6834685742594241
Epoch: 59, loss: 0.06164884072233428, time cost: 146.64348363876343
Val auc: 0.8757783616047263, f1: 0.7511375594995112, accuracy: 0.9562986260552888, precision: 0.7760359685994511, recall: 0.7308933011018046
Epoch: 60, loss: 0.05837086551227011, time cost: 150.43916082382202
Val auc: 0.8705626221296663, f1: 0.7332562750997728, accuracy: 0.9533189869226949, precision: 0.7574947332067001, recall: 0.7137487041641056
Epoch: 61, loss: 0.05934151664778993, time cost: 151.76673579216003
Val auc: 0.8663597561535004, f1: 0.7122089401279674, accuracy: 0.9569607680847542, precision: 0.7993288900281978, recall: 0.6673810009816243
Epoch: 62, loss: 0.06030335539096111, time cost: 155.12141942977905
Val auc: 0.8732575020870984, f1: 0.7332573860901741, accuracy: 0.9602714782320808, precision: 0.8313962657237598, recall: 0.6831423217709605
Epoch: 63, loss: 0.05737370373429479, time cost: 158.02644872665405
Val auc: 0.8746227168059595, f1: 0.7445024695655393, accuracy: 0.9561330905479225, precision: 0.7765757443328588, recall: 0.7199030645945524
Epoch: 64, loss: 0.05674346929063668, time cost: 156.11846256256104
Val auc: 0.8714748676641927, f1: 0.7344896856441852, accuracy: 0.9549743419963582, precision: 0.7696781450899615, recall: 0.7083899066998156
Epoch: 65, loss: 0.05619586438678943, time cost: 159.81510400772095
Val auc: 0.8780354669137548, f1: 0.731703323655358, accuracy: 0.9556364840258236, precision: 0.776086052304449, recall: 0.7009506045705164
Epoch: 66, loss: 0.05652127302511855, time cost: 160.53126764297485
Val auc: 0.8586174233736685, f1: 0.7239710945507591, accuracy: 0.9574573746068532, precision: 0.7987055229762601, recall: 0.681660711173087
Epoch: 67, loss: 0.05926148319902184, time cost: 162.0319049358368
Val auc: 0.8721480142748366, f1: 0.7428289953208168, accuracy: 0.9591127296805164, precision: 0.8071912882143862, recall: 0.702780829426713
Epoch: 68, loss: 0.053444632622706996, time cost: 151.80301713943481
Val auc: 0.8689735030228526, f1: 0.7336589486100126, accuracy: 0.9591127296805164, precision: 0.8137440460193386, recall: 0.6887625799289928
Epoch: 69, loss: 0.05301216293361273, time cost: 147.06153106689453
Val auc: 0.8769431804629231, f1: 0.7553257332494598, accuracy: 0.9576229101142195, precision: 0.785552589383429, recall: 0.7315905296184508
Epoch: 70, loss: 0.053786134632589584, time cost: 148.9591052532196
Val auc: 0.8815233296331293, f1: 0.7616835719895192, accuracy: 0.9572918390994868, precision: 0.7806646392958493, recall: 0.7454344719870095
Epoch: 71, loss: 0.049948875028807835, time cost: 147.0840082168579
Val auc: 0.8765968597194571, f1: 0.7558571044805216, accuracy: 0.9577884456215858, precision: 0.7867861345688949, recall: 0.7316776831830316
Epoch: 72, loss: 0.053179018266566166, time cost: 146.72089171409607
Val auc: 0.8691194279056539, f1: 0.7536662218268091, accuracy: 0.9562986260552888, precision: 0.7753583411415711, recall: 0.735566050934378
Epoch: 73, loss: 0.05202776869876428, time cost: 146.91876101493835
Val auc: 0.8762800679797804, f1: 0.7450568444539043, accuracy: 0.9543121999668929, precision: 0.7628402337377584, recall: 0.7298474583268351
Epoch: 74, loss: 0.04937956642426618, time cost: 147.32531237602234
Val auc: 0.8691830729429465, f1: 0.7508136734395168, accuracy: 0.9589471941731501, precision: 0.8003942139564457, recall: 0.7167119253598525
Epoch: 75, loss: 0.049492506260001984, time cost: 146.15864658355713
Val auc: 0.8684738034732989, f1: 0.6820078370172887, accuracy: 0.9549743419963582, precision: 0.7886714116251483, recall: 0.6367410759336899
Epoch: 76, loss: 0.05081847384739835, time cost: 145.52657961845398
Val auc: 0.8753672490665395, f1: 0.7272030181433344, accuracy: 0.9574573746068532, precision: 0.7968622396313869, recall: 0.6863334610056604
Epoch: 77, loss: 0.04776891153137963, time cost: 147.62321305274963
Val auc: 0.8711382943588708, f1: 0.7366519357838877, accuracy: 0.9584505876510512, precision: 0.8031774735439423, recall: 0.696201882058292
Epoch: 78, loss: 0.050456745113741173, time cost: 144.64904165267944
Val auc: 0.8722807514472077, f1: 0.7417820156411677, accuracy: 0.9561330905479225, precision: 0.7773826836448764, recall: 0.7152303147619791
Epoch: 79, loss: 0.04771330737852835, time cost: 154.72717833518982
Val auc: 0.8828833839435613, f1: 0.7608829994710078, accuracy: 0.9572918390994868, precision: 0.7809151058914284, recall: 0.7438768887094851
Epoch: 80, loss: 0.04612871984372268, time cost: 154.72622680664062
Val auc: 0.8786329275341046, f1: 0.752695184735027, accuracy: 0.9567952325773879, precision: 0.7795331880006213, recall: 0.731154761795547
Epoch: 81, loss: 0.04621264993775267, time cost: 149.65075039863586
Val auc: 0.8722076456611285, f1: 0.7239003646407742, accuracy: 0.9581195166363184, precision: 0.8073395037649089, recall: 0.6788941588763612
Epoch: 82, loss: 0.045677542233386555, time cost: 148.79332852363586
Val auc: 0.8693456258084641, f1: 0.7505476988053297, accuracy: 0.9514980963416653, precision: 0.7464178988628867, recall: 0.7548447634468776
Epoch: 83, loss: 0.0451070254601471, time cost: 146.01850938796997
Val auc: 0.8734062938634717, f1: 0.7345896214105195, accuracy: 0.9531534514153286, precision: 0.7562432646753827, recall: 0.7167767171545738
Epoch: 84, loss: 0.04384203925560992, time cost: 149.41694974899292
Val auc: 0.8755963138629211, f1: 0.7520844509820888, accuracy: 0.9587816586657838, precision: 0.7979560261852561, recall: 0.7197399383503207
Epoch: 85, loss: 0.04350567573832499, time cost: 146.91621375083923
Val auc: 0.8730740208985073, f1: 0.7485535900104059, accuracy: 0.9562986260552888, precision: 0.7767591209130382, recall: 0.7262205512692311
Epoch: 86, loss: 0.045022848372658096, time cost: 148.34127259254456
Val auc: 0.8732190857132374, f1: 0.7343467139642776, accuracy: 0.9602714782320808, precision: 0.830300435785696, recall: 0.6846999050484849
Epoch: 87, loss: 0.0462516649785611, time cost: 152.43044662475586
Val auc: 0.8748302799005533, f1: 0.7117817525553215, accuracy: 0.9579539811289521, precision: 0.814012384761493, recall: 0.6632311725365356
Epoch: 88, loss: 0.04302433658357676, time cost: 149.13539719581604
Val auc: 0.8823653362751483, f1: 0.7570271986334025, accuracy: 0.9558020195331899, precision: 0.7709666951171805, recall: 0.7446500899057824
Epoch: 89, loss: 0.046191772899112186, time cost: 147.61072492599487
Val auc: 0.8626689173692467, f1: 0.7283255955451503, accuracy: 0.9465320311206754, precision: 0.7220027570314589, recall: 0.7350967404566846
Epoch: 90, loss: 0.04259778529841889, time cost: 148.72074580192566
Val auc: 0.8766266754126033, f1: 0.7545902407906973, accuracy: 0.9571263035921205, precision: 0.7816275460959862, recall: 0.732886652202233
Epoch: 91, loss: 0.03809500011607065, time cost: 147.71936655044556
Val auc: 0.8665306230103759, f1: 0.7539956118191797, accuracy: 0.9548088064889919, precision: 0.7648482394230398, recall: 0.7441271685182976
Epoch: 92, loss: 0.04178481220125078, time cost: 150.4158272743225
Val auc: 0.8778172963129456, f1: 0.7559578687083028, accuracy: 0.9572918390994868, precision: 0.7825308236919357, recall: 0.7345313890443382
Epoch: 93, loss: 0.040627231401903136, time cost: 146.68259692192078
Val auc: 0.8701801785271964, f1: 0.7497232496785056, accuracy: 0.9586161231584175, precision: 0.7975010516663594, recall: 0.716537618230691
Epoch: 94, loss: 0.040243911070262525, time cost: 144.9978485107422
Val auc: 0.8710861168958652, f1: 0.7331976028833078, accuracy: 0.9529879159079623, precision: 0.7552561470251677, recall: 0.7151319803124685
Epoch: 95, loss: 0.038155501607704805, time cost: 140.4113323688507
Val auc: 0.8660828142344708, f1: 0.7235447314118353, accuracy: 0.9562986260552888, precision: 0.7855552852022096, recall: 0.6857233860535948
Epoch: 96, loss: 0.03957862634346023, time cost: 149.20306491851807
Val auc: 0.8686406566791741, f1: 0.7006442569194121, accuracy: 0.9551398775037245, precision: 0.7820365397906943, recall: 0.6586343953836133
Epoch: 97, loss: 0.037351644312677616, time cost: 144.9636790752411
Val auc: 0.8694603015513335, f1: 0.747877955165194, accuracy: 0.9558020195331899, precision: 0.7730356639074101, recall: 0.7275166738530132
Epoch: 98, loss: 0.03886440495733876, time cost: 141.39644622802734
Val auc: 0.8631654633358715, f1: 0.724701439404847, accuracy: 0.9543121999668929, precision: 0.7663569208664553, recall: 0.6955806262212967
Epoch: 99, loss: 0.03778387653968624, time cost: 148.64728808403015
Val auc: 0.8600353889342494, f1: 0.7264846255189044, accuracy: 0.949346134745903, precision: 0.734082757793941, recall: 0.719444935001789

Under the condition of auc, best idx: 79
Best F1 score 0.7616835719895192 found at epoch count: 70 and patience_count: 29
Test auc: 0.8434475427281817, f1: 0.7257040783992457, accuracy: 0.9533189869226949, precision: 0.7583501491715716, recall: 0.7012880379439098

Under the condition of f1, best idx: 70
Test auc: 0.8411950244488683, f1: 0.7223902452322444, accuracy: 0.9511670253269326, precision: 0.7439485674326876, recall: 0.704827791436933

Group by DD
Test number: 1/3

[NEW TEST]  - Model info:
{
	"data": "DD",
	"lr": 0.001,
	"batchsize": 256,
	"nepoch": 100,
	"hdim": 128,
	"width": 4,
	"depth": 6,
	"dropout": 0.4,
	"normalize": 1,
	"beta": 0.999,
	"gamma": 1.5,
	"decay": 0,
	"seed": 10,
	"patience": 50,
	"intergraph": "sage",
	"alltests": 1,
	"datagroup": 5
}
Loading dataset: DD
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):
/usr/local/lib/python3.10/dist-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location)
Starts training...
Epoch: 0, loss: 0.5340521261096001, time cost: 87.13074016571045
Val auc: 0.8250790305584826, f1: 0.43311160384331115, accuracy: 0.4858757062146893, precision: 0.6425716189207195, recall: 0.5563751317175974
Epoch: 1, loss: 0.517505943775177, time cost: 83.88526105880737
Val auc: 0.8415437302423603, f1: 0.32358394188202355, accuracy: 0.4293785310734463, precision: 0.7097701149425287, recall: 0.5144230769230769
Epoch: 2, loss: 0.5037363916635513, time cost: 69.94997382164001
Val auc: 0.8439146469968387, f1: 0.31322276323797926, accuracy: 0.423728813559322, precision: 0.7085714285714286, recall: 0.5096153846153846
Epoch: 3, loss: 0.48910124599933624, time cost: 77.62838959693909
Val auc: 0.8315331928345627, f1: 0.3730814639905549, accuracy: 0.4576271186440678, precision: 0.7159763313609467, recall: 0.5384615384615384
Epoch: 4, loss: 0.4784729853272438, time cost: 79.23010087013245
Val auc: 0.8263962065331928, f1: 0.4701336675020885, accuracy: 0.5141242937853108, precision: 0.6835777126099707, recall: 0.5824552160168599
Epoch: 5, loss: 0.4548371657729149, time cost: 66.53243589401245
Val auc: 0.8261327713382508, f1: 0.4894230769230769, accuracy: 0.5254237288135594, precision: 0.6740957717778909, recall: 0.5900289778714436
Epoch: 6, loss: 0.4499465599656105, time cost: 73.36155867576599
Val auc: 0.8269230769230769, f1: 0.4938501291989664, accuracy: 0.5310734463276836, precision: 0.6935526315789474, recall: 0.5968782929399368
Epoch: 7, loss: 0.44679900258779526, time cost: 81.3026065826416
Val auc: 0.8257376185458377, f1: 0.5579862151633204, accuracy: 0.576271186440678, precision: 0.6923745173745174, recall: 0.6312565858798735
Epoch: 8, loss: 0.43279799073934555, time cost: 86.90483570098877
Val auc: 0.82731822971549, f1: 0.6280190112839082, accuracy: 0.632768361581921, precision: 0.7000912964090079, recall: 0.673208640674394
Epoch: 9, loss: 0.427613228559494, time cost: 84.15201568603516
Val auc: 0.8295574288724973, f1: 0.6651274651274651, accuracy: 0.6666666666666666, precision: 0.7145986433013001, recall: 0.7000131717597471
Epoch: 10, loss: 0.4173501431941986, time cost: 88.23848676681519
Val auc: 0.8379873551106428, f1: 0.7117171781688116, accuracy: 0.711864406779661, precision: 0.7429549114331724, recall: 0.7384747102212856
Epoch: 11, loss: 0.3981691002845764, time cost: 67.90847682952881
Val auc: 0.8395679662802951, f1: 0.751213902376693, accuracy: 0.751412429378531, precision: 0.7655400155400156, recall: 0.7700869336143308
Epoch: 12, loss: 0.3926158472895622, time cost: 69.03435325622559
Val auc: 0.8369336143308747, f1: 0.7768114067703449, accuracy: 0.7796610169491526, precision: 0.775921658986175, recall: 0.7839172813487882
Epoch: 13, loss: 0.37612996250391006, time cost: 84.91081428527832
Val auc: 0.8369336143308745, f1: 0.7707847707847708, accuracy: 0.7740112994350282, precision: 0.7696103563188926, recall: 0.7770679662802951
Epoch: 14, loss: 0.38244228065013885, time cost: 95.45488023757935
Val auc: 0.846022128556375, f1: 0.7937062937062938, accuracy: 0.7966101694915254, precision: 0.7922968469623173, recall: 0.800381981032666
Epoch: 15, loss: 0.38381558656692505, time cost: 99.73441004753113
Val auc: 0.8560326659641728, f1: 0.8171015241539654, accuracy: 0.8192090395480226, precision: 0.8162404092071611, recall: 0.8257376185458377
Epoch: 16, loss: 0.3746349439024925, time cost: 74.74995017051697
Val auc: 0.8651211801896733, f1: 0.7847542242703534, accuracy: 0.7853107344632768, precision: 0.7933247753530167, recall: 0.8009747102212856
Epoch: 17, loss: 0.3689730688929558, time cost: 86.76065587997437
Val auc: 0.863935721812434, f1: 0.7907199693222126, accuracy: 0.7909604519774012, precision: 0.8038620511495738, recall: 0.8098656480505795
Epoch: 18, loss: 0.3629162013530731, time cost: 85.45520210266113
Val auc: 0.857613277133825, f1: 0.795138888888889, accuracy: 0.7966101694915254, precision: 0.7971144024514811, recall: 0.8065068493150684
Epoch: 19, loss: 0.3534497991204262, time cost: 92.45536923408508
Val auc: 0.8585353003161222, f1: 0.7997025445374892, accuracy: 0.8022598870056498, precision: 0.79857910906298, recall: 0.8072312961011592
Epoch: 20, loss: 0.35526467859745026, time cost: 72.7889997959137
Val auc: 0.8711801896733403, f1: 0.812023299971036, accuracy: 0.8135593220338984, precision: 0.8130745658835546, recall: 0.8229715489989462
Epoch: 21, loss: 0.3513522818684578, time cost: 92.08740735054016
Val auc: 0.8715753424657534, f1: 0.7958215842091771, accuracy: 0.7966101694915254, precision: 0.8018433179723503, recall: 0.8105900948366702
Epoch: 22, loss: 0.3578561022877693, time cost: 85.63500642776489
Val auc: 0.8694678609062171, f1: 0.8056703694135882, accuracy: 0.807909604519774, precision: 0.804923273657289, recall: 0.8140806111696522
Epoch: 23, loss: 0.3429778590798378, time cost: 74.98429751396179
Val auc: 0.8645943097997892, f1: 0.7937062937062938, accuracy: 0.7966101694915254, precision: 0.7922968469623173, recall: 0.800381981032666
Epoch: 24, loss: 0.3329395353794098, time cost: 89.55106091499329
Val auc: 0.8670969441517387, f1: 0.8175257731958763, accuracy: 0.8192090395480226, precision: 0.8178160919540229, recall: 0.8277792413066385
Epoch: 25, loss: 0.339241698384285, time cost: 69.32265853881836
Val auc: 0.8620916754478397, f1: 0.7583657976226151, accuracy: 0.768361581920904, precision: 0.7621424716675662, recall: 0.7559272918861959
Epoch: 26, loss: 0.3359697237610817, time cost: 68.04305171966553
Val auc: 0.8636722866174921, f1: 0.780859963192237, accuracy: 0.7909604519774012, precision: 0.7872645372645373, recall: 0.7771996838777661
Epoch: 27, loss: 0.3372972384095192, time cost: 76.51296854019165
Val auc: 0.8669652265542677, f1: 0.8013468013468014, accuracy: 0.8022598870056498, precision: 0.8062020460358057, recall: 0.8153977871443625
Epoch: 28, loss: 0.3250405490398407, time cost: 81.45323896408081
Val auc: 0.8695995785036881, f1: 0.8013468013468014, accuracy: 0.8022598870056498, precision: 0.8062020460358057, recall: 0.8153977871443625
Epoch: 29, loss: 0.3359624445438385, time cost: 102.24072527885437
Val auc: 0.8565595363540569, f1: 0.7690145557972228, accuracy: 0.7796610169491526, precision: 0.7751842751842752, recall: 0.7655426765015806
Epoch: 30, loss: 0.32110556960105896, time cost: 99.67692804336548
Val auc: 0.8491833508956796, f1: 0.7515831992606032, accuracy: 0.768361581920904, precision: 0.7702839756592292, recall: 0.7457191780821918
Epoch: 31, loss: 0.33104175329208374, time cost: 99.62616896629333
Val auc: 0.8532665964172812, f1: 0.7701528318849264, accuracy: 0.7796610169491526, precision: 0.7740825688073394, recall: 0.7675842992623815
Epoch: 32, loss: 0.3277033045887947, time cost: 91.7693862915039
Val auc: 0.8594573234984193, f1: 0.7958215842091771, accuracy: 0.7966101694915254, precision: 0.8018433179723503, recall: 0.8105900948366702
Epoch: 33, loss: 0.33245749771595, time cost: 88.51236653327942
Val auc: 0.8610379346680717, f1: 0.795138888888889, accuracy: 0.7966101694915254, precision: 0.7971144024514811, recall: 0.8065068493150684
Epoch: 34, loss: 0.35917291045188904, time cost: 101.73692870140076
Val auc: 0.8639357218124342, f1: 0.7955070603337613, accuracy: 0.7966101694915254, precision: 0.7993227702530028, recall: 0.8085484720758693
Epoch: 35, loss: 0.32886750251054764, time cost: 89.09132742881775
Val auc: 0.8589304531085352, f1: 0.7833118556701031, accuracy: 0.7853107344632768, precision: 0.7839080459770116, recall: 0.7928082191780822
Epoch: 36, loss: 0.3261703550815582, time cost: 94.87327098846436
Val auc: 0.8537934668071654, f1: 0.7887760038703435, accuracy: 0.7909604519774012, precision: 0.7887170968566317, recall: 0.7976159114857745
Epoch: 37, loss: 0.3193817287683487, time cost: 68.81067132949829
Val auc: 0.8540569020021074, f1: 0.7909997376016794, accuracy: 0.7966101694915254, precision: 0.79, recall: 0.7922154899894626
Epoch: 38, loss: 0.31876156479120255, time cost: 86.77319574356079
Val auc: 0.8530031612223392, f1: 0.8026108632904749, accuracy: 0.807909604519774, precision: 0.8015686274509803, recall: 0.803872497365648
Epoch: 39, loss: 0.32341962307691574, time cost: 94.25730586051941
Val auc: 0.8645943097997892, f1: 0.7997025445374892, accuracy: 0.8022598870056498, precision: 0.79857910906298, recall: 0.8072312961011592
Epoch: 40, loss: 0.31388456374406815, time cost: 89.27286005020142
Val auc: 0.8657797681770284, f1: 0.812023299971036, accuracy: 0.8135593220338984, precision: 0.8130745658835546, recall: 0.8229715489989462
Epoch: 41, loss: 0.30958661437034607, time cost: 104.66310524940491
Val auc: 0.8635405690200211, f1: 0.7997025445374892, accuracy: 0.8022598870056498, precision: 0.79857910906298, recall: 0.8072312961011592
Epoch: 42, loss: 0.31114359200000763, time cost: 87.52388381958008
Val auc: 0.8540569020021075, f1: 0.7901738672286618, accuracy: 0.7966101694915254, precision: 0.7901738672286618, recall: 0.7901738672286618
Epoch: 43, loss: 0.3176377862691879, time cost: 99.11418509483337
Val auc: 0.8605110642781875, f1: 0.8149019607843138, accuracy: 0.8192090395480226, precision: 0.8131168831168831, recall: 0.8175711275026343
Epoch: 44, loss: 0.31431493908166885, time cost: 89.33600521087646
Val auc: 0.8589304531085353, f1: 0.7942392146732111, accuracy: 0.7966101694915254, precision: 0.7936061381074169, recall: 0.8024236037934669
Epoch: 45, loss: 0.3048657327890396, time cost: 86.5562059879303
Val auc: 0.8576132771338251, f1: 0.7882569756539171, accuracy: 0.7909604519774012, precision: 0.7872503840245776, recall: 0.7955742887249737
Epoch: 46, loss: 0.3200126737356186, time cost: 78.12991857528687
Val auc: 0.8591938883034773, f1: 0.8166278166278167, accuracy: 0.8192090395480226, precision: 0.814983337605742, recall: 0.8236959957850369
Epoch: 47, loss: 0.34524301439523697, time cost: 84.92682337760925
Val auc: 0.8627502634351949, f1: 0.8006307726965534, accuracy: 0.8022598870056498, precision: 0.8017747701736466, recall: 0.8113145416227607
Epoch: 48, loss: 0.30825165659189224, time cost: 70.47909212112427
Val auc: 0.8555057955742887, f1: 0.7683615819209039, accuracy: 0.768361581920904, precision: 0.7926765015806112, recall: 0.7926765015806112
Epoch: 49, loss: 0.3093908727169037, time cost: 85.9096429347992
Val auc: 0.8591938883034774, f1: 0.7795484303643854, accuracy: 0.7796610169491526, precision: 0.7960389610389611, recall: 0.8002502634351949
Epoch: 50, loss: 0.3097836598753929, time cost: 103.67652416229248
Val auc: 0.8622233930453108, f1: 0.7971844819119331, accuracy: 0.8022598870056498, precision: 0.7957920792079207, recall: 0.7990648050579557
Epoch: 51, loss: 0.30102023109793663, time cost: 84.57220888137817
Val auc: 0.857876712328767, f1: 0.7955782874113183, accuracy: 0.8022598870056498, precision: 0.7962301587301588, recall: 0.7949815595363541
Epoch: 52, loss: 0.36743271350860596, time cost: 84.72534704208374
Val auc: 0.8593256059009484, f1: 0.7947164948453608, accuracy: 0.7966101694915254, precision: 0.7952107279693487, recall: 0.8044652265542676
Epoch: 53, loss: 0.32780902087688446, time cost: 86.60190510749817
Val auc: 0.8614330874604846, f1: 0.7456328042665985, accuracy: 0.7457627118644068, precision: 0.7785829307568438, recall: 0.7734457323498419
Epoch: 54, loss: 0.3059326857328415, time cost: 76.25971245765686
Val auc: 0.8609062170706007, f1: 0.7782738573218129, accuracy: 0.7796610169491526, precision: 0.7812260536398468, recall: 0.7900421496311907
Epoch: 55, loss: 0.30577974021434784, time cost: 77.47700238227844
Val auc: 0.8598524762908325, f1: 0.7755006675567424, accuracy: 0.7853107344632768, precision: 0.7805970149253731, recall: 0.7723919915700738
Epoch: 56, loss: 0.2991526201367378, time cost: 86.60948181152344
Val auc: 0.8648577449947313, f1: 0.7946839889967852, accuracy: 0.8022598870056498, precision: 0.7969292389853138, recall: 0.7929399367755532
Epoch: 57, loss: 0.2998868003487587, time cost: 91.43164801597595
Val auc: 0.8643308746048471, f1: 0.812023299971036, accuracy: 0.8135593220338984, precision: 0.8130745658835546, recall: 0.8229715489989462
Epoch: 58, loss: 0.30798226594924927, time cost: 90.0182375907898
Val auc: 0.8597207586933614, f1: 0.7960829493087558, accuracy: 0.7966101694915254, precision: 0.8046854942233633, recall: 0.812631717597471
Epoch: 59, loss: 0.31619128584861755, time cost: 100.0066146850586
Val auc: 0.8605110642781876, f1: 0.8071648295308895, accuracy: 0.807909604519774, precision: 0.8131720430107527, recall: 0.8222471022128557
Epoch: 60, loss: 0.320700079202652, time cost: 99.48854613304138
Val auc: 0.8635405690200211, f1: 0.7822455322455322, accuracy: 0.7853107344632768, precision: 0.7809536016406049, recall: 0.7887249736564805
Epoch: 61, loss: 0.28939833864569664, time cost: 84.13689017295837
Val auc: 0.8649894625922022, f1: 0.7971844819119331, accuracy: 0.8022598870056498, precision: 0.7957920792079207, recall: 0.7990648050579557
Epoch: 62, loss: 0.3224977105855942, time cost: 97.57522439956665
Val auc: 0.863277133825079, f1: 0.7870451663252365, accuracy: 0.7909604519774012, precision: 0.785180412371134, recall: 0.7914910432033719
Epoch: 63, loss: 0.3154512420296669, time cost: 89.60395503044128
Val auc: 0.857086406743941, f1: 0.795138888888889, accuracy: 0.7966101694915254, precision: 0.7971144024514811, recall: 0.8065068493150684
Epoch: 64, loss: 0.2957781292498112, time cost: 91.71536493301392
Val auc: 0.8597207586933614, f1: 0.772785622593068, accuracy: 0.7740112994350282, precision: 0.7767058522872476, recall: 0.7852344573234984
Epoch: 65, loss: 0.2983943447470665, time cost: 80.16785955429077
Val auc: 0.8589304531085353, f1: 0.7855950237354722, accuracy: 0.7909604519774012, precision: 0.7842626367899947, recall: 0.7874077976817703
Epoch: 66, loss: 0.29748260974884033, time cost: 93.8474771976471
Val auc: 0.8615648050579556, f1: 0.7883337762423597, accuracy: 0.7966101694915254, precision: 0.7914653784219001, recall: 0.78609062170706
Epoch: 67, loss: 0.35040534287691116, time cost: 97.89562654495239
Val auc: 0.86340885142255, f1: 0.8026108632904749, accuracy: 0.807909604519774, precision: 0.8015686274509803, recall: 0.803872497365648
Epoch: 68, loss: 0.28522907197475433, time cost: 81.48886394500732
Val auc: 0.8552423603793468, f1: 0.8039994788952579, accuracy: 0.807909604519774, precision: 0.8019891500904159, recall: 0.8079557428872497
Epoch: 69, loss: 0.2896728366613388, time cost: 77.01366853713989
Val auc: 0.8636722866174922, f1: 0.7887760038703435, accuracy: 0.7909604519774012, precision: 0.7887170968566317, recall: 0.7976159114857745
Epoch: 70, loss: 0.27281297743320465, time cost: 95.25405049324036
Val auc: 0.8699947312961012, f1: 0.8161038961038962, accuracy: 0.8192090395480226, precision: 0.8140432098765432, recall: 0.821654373024236
Epoch: 71, loss: 0.317722637206316, time cost: 76.52486371994019
Val auc: 0.8607744994731296, f1: 0.7882569756539171, accuracy: 0.7909604519774012, precision: 0.7872503840245776, recall: 0.7955742887249737
Epoch: 72, loss: 0.27560458332300186, time cost: 86.94803500175476
Val auc: 0.857086406743941, f1: 0.7789554580678215, accuracy: 0.7796610169491526, precision: 0.7862086644450141, recall: 0.7941253951527925
Epoch: 73, loss: 0.2902471050620079, time cost: 92.72239661216736
Val auc: 0.8659114857744995, f1: 0.7947164948453608, accuracy: 0.7966101694915254, precision: 0.7952107279693487, recall: 0.8044652265542676
Epoch: 74, loss: 0.27186106890439987, time cost: 88.25840616226196
Val auc: 0.8682824025289778, f1: 0.8026108632904749, accuracy: 0.807909604519774, precision: 0.8015686274509803, recall: 0.803872497365648
Epoch: 75, loss: 0.30380311235785484, time cost: 87.37019276618958
Val auc: 0.8663066385669125, f1: 0.8163961853772795, accuracy: 0.8248587570621468, precision: 0.8235053235053236, recall: 0.8121707060063224

Under the condition of auc, best idx: 21
Best F1 score 0.8175257731958763 found at epoch count: 24 and patience_count: 51
Test auc: 0.7953482328482329, f1: 0.6785476665716187, accuracy: 0.6797752808988764, precision: 0.723464458247067, recall: 0.7103690228690229

Under the condition of f1, best idx: 24
Test auc: 0.7943087318087317, f1: 0.7078282828282828, accuracy: 0.7078651685393258, precision: 0.7249742002063984, recall: 0.7266112266112266

Group by P388
Test number: 2/3

[NEW TEST]  - Model info:
{
	"data": "P388",
	"lr": 0.001,
	"batchsize": 256,
	"nepoch": 100,
	"hdim": 128,
	"width": 4,
	"depth": 6,
	"dropout": 0.4,
	"normalize": 1,
	"beta": 0.999,
	"gamma": 1.5,
	"decay": 0,
	"seed": 10,
	"patience": 50,
	"intergraph": "sage",
	"alltests": 1,
	"datagroup": 5
}
Loading dataset: P388
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):
/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):
/usr/local/lib/python3.10/dist-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location)
Starts training...
Epoch: 0, loss: 0.1997975928610877, time cost: 138.3931188583374
Val auc: 0.7361322402107319, f1: 0.5054166970884341, accuracy: 0.944864169747629, precision: 0.7644481129543137, recall: 0.5097194680399759
Epoch: 1, loss: 0.15153359288447782, time cost: 136.00117993354797
Val auc: 0.7601582462682885, f1: 0.5394087160764891, accuracy: 0.9440604404436586, precision: 0.7071027633851468, recall: 0.5283925770266671
Epoch: 2, loss: 0.14769191778542703, time cost: 136.84521913528442
Val auc: 0.7655732974220855, f1: 0.5294429106312166, accuracy: 0.9434174570004822, precision: 0.6807798563422527, recall: 0.5225954755773917
Epoch: 3, loss: 0.14382410212828403, time cost: 136.49926233291626
Val auc: 0.7842572587089709, f1: 0.5287683398652565, accuracy: 0.9451856614692171, precision: 0.7591520380152708, recall: 0.5221673030060872